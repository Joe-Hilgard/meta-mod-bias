---
title: "Meta-Analysis"
author: "Olivia Cody"
date: "1/30/2018"
output:
  pdf_document: default
  html_document: default
---

Next steps:
Plot:
- RMSE
Parameters would be:
- B1, b2, b3
   - Ggplot: x= b1, b2, b3; y = obs value; jitter; shape = est (na√Øve, additive PET, interactive pet; error bar = quantile 



####*Techniques for detecting and adjusting bias*
**Ways to detect bias**
- Funnel plots
- Forest plots?
- Egger Test (looks at slope)

**Ways to detect and adjust bias**
- Trim and fill
- PET (just looks at intercept) and PEESE
- P-curve
- P-uniform

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(MASS)
library(tidyverse)
library(truncnorm)
library(truncdist)
library(pwr)
library(compiler)
library(metafor)

# load study-simulating functions
source("sim-studies/sim-studies.R", chdir=TRUE)
```

*k* the number of studies in the MA
*delta* the true effect (or the average of the true effects if heterogeneity exists)
*tau* the SD around the true effect
*empN* a logical, whether to use the empirical per-group N distribution
*maxN* the max possible group size that could be created *this needs to be set higher than what can actually be generated--it doesn't mean you get bigger samples
*minN* the min of the truncated normal for sample size
*meanN* the average of the truncated normal for sample size

*selProp* the proportion of the sample affected by bias
*qrpEnv* the qrp environment that produced the literature: 'none', 'low', 'med', 'high'
*empN.boost* A constant that is added to the empirical effect sizes

####*Code that does it all in one*
```{r}

# Function that runs dataMA three times + fake data
modMA <- function(k, selProp = 0, qrpEnv = "none", empN.boost = 0) {
  d1 <- dataMA(k = k, delta = .2, tau = 0, 
               empN = 0, maxN = 200, minN = 20, meanN = 50, 
               selProp = selProp, qrpEnv = qrpEnv, empN.boost = empN.boost)
  d2 <- dataMA(k = k, delta = .5, tau = 0, 
               empN = 0, maxN = 200, minN = 20, meanN = 50, 
               selProp = selProp, qrpEnv = qrpEnv, empN.boost = empN.boost)
  d3 <- dataMA(k = k, delta = .8, tau = 0, 
               empN = 0, maxN = 200, minN = 20, meanN = 50, 
               selProp = selProp, qrpEnv = qrpEnv, empN.boost = empN.boost)
  return(bind_rows(data.frame(d1), data.frame(d2), data.frame(d3), .id = "id"))
}


# function to analyze results of dataMA
inspectMA <- function(dataset) {
  # basic model
  rmamod <- rma(yi = d, sei = se, data = dataset)
  # test for moderator
  moderation.test <- rma(yi = d, sei = se, 
                         mods = ~id, data = dataset)
  # test for small-study effect
  egger.PET.test <- rma(yi = d, sei = se,
                    mods = ~se, data = dataset)
  # test for moderator after adjustment for small-study
  joint.test.additive <- rma(yi = d, sei = se,
                    mods = ~id + se, data = dataset)
  joint.test.interactive <- rma(yi = d, sei = se,
                             mods = ~id * se, data = dataset)
  # not sure how to interpret these parameters in the interactive model
  # test for moderator in hedges & vevea weight model
  # return test results
  out = data.frame(d.obs = summary(rmamod)$b[1],
                    se.obs = summary(rmamod)$se[1],
                    d.p = summary(rmamod)$pval[1],
                    # Moderators
                    # Note that .1 is the intercept, reference group
                    mod.b.obs.1 = summary(moderation.test)$b[1],
                    mod.b.obs.2 = summary(moderation.test)$b[2],
                    mod.b.obs.3 = summary(moderation.test)$b[3],
                    mod.p.1 = summary(moderation.test)$pval[1],
                    mod.p.2 = summary(moderation.test)$pval[2],
                    mod.p.3 = summary(moderation.test)$pval[3],
                    # Egger / PET
                    d.obs.pet = summary(egger.PET.test)$b[1],
                    p.pet = summary(egger.PET.test)$pval[1],
                    b.egger = summary(egger.PET.test)$b[2],
                    p.egger = summary(egger.PET.test)$pval[2],
                    # joint PET-RMA tests
                    #Additive model 
                    joint.add.b1 = summary(joint.test.additive)$b[1],
                    joint.add.b2 = summary(joint.test.additive)$b[2],
                    joint.add.b3 = summary(joint.test.additive)$b[3],
                    joint.add.b.egger = summary(joint.test.additive)$b[4],
                    joint.add.p1 = summary(joint.test.additive)$pval[1],
                    joint.add.p2 = summary(joint.test.additive)$pval[2],
                    joint.add.p3 = summary(joint.test.additive)$pval[3],
                    joint.add.p.egger = summary(joint.test.additive)$pval[4],
                    #Interactive model
                    joint.inter.b1 = summary(joint.test.interactive)$b[1],
                    joint.inter.b2 = summary(joint.test.interactive)$b[2],
                    joint.inter.b3 = summary(joint.test.interactive)$b[3],
                    joint.inter.b1.egger = summary(joint.test.interactive)$b[4],
                    joint.inter.b2.egger = summary(joint.test.interactive)$b[5],
                    joint.inter.b3.egger = summary(joint.test.interactive)$b[6],
                    joint.inter.p1 = summary(joint.test.interactive)$pval[1],
                    joint.inter.p2 = summary(joint.test.interactive)$pval[2],
                    joint.inter.p3 = summary(joint.test.interactive)$pval[3],
                    joint.inter.p1.egger = summary(joint.test.interactive)$pval[4],
                    joint.inter.p2.egger = summary(joint.test.interactive)$pval[5],
                    joint.inter.p3.egger = summary(joint.test.interactive)$pval[6]
                    )
  return(data.frame(out))
  }

# example data set for testing & debugging
#final_output.cvs?

# function to make various visuals of MA: (?)

visualizeMA <- function(dataset){
  visu.data = plot(dataset)
  return(visu.data)}

#________________________________________________________________________________
is_sig <- function(x) x < .05

summarize_run <- function(x) {
  # Get estimates of d, moderator parameters, bias parameter, bias-adjusted PET
  x.est <- x %>% 
    summarize_at(.vars = vars(d.obs, mod.obs.b1:mod.obs.b3, d.obs.pet, 
                              joint.add.b1:joint.add.b3, joint.inter.b1:joint.inter.b3),
                 .funs = funs(mean)) %>% 
    # make cell means (NOTE: ASSUMES DUMMY CODING)
    # Might be a simpler way... lsmeans package?
    # use transmute to drop all other columns
    transmute(d.obs,
              d.obs.pet,
              d1.obs = mod.obs.b1,
              d2.obs = mod.obs.b1 + mod.obs.b2,
              d3.obs = mod.obs.b1 + mod.obs.b3, 
              joint.add.d1.obs = joint.add.b1,
              joint.add.d2.obs = joint.add.b1 + joint.add.b2,
              joint.add.d3.obs = joint.add.b1 + joint.add.b3,
              joint.inter.d1.obs = joint.inter.b1,
              joint.inter.d2.obs = joint.inter.b1 + joint.inter.b2,
              joint.inter.d3.obs = joint.inter.b1 + joint.inter.b3)

  # Get power (or Type I) rates for each p-value test
  x.pow <- x %>% 
    summarize_at(.vars = vars(d.p, mod.p.1:mod.p.3, 
                              joint.add.p1:joint.add.p3,
                              joint.inter.p1:joint.inter.p3),
                 .funs = funs(mean(is_sig(.))))
  
  return(bind_cols(x.est, x.pow))
}

# Plot observed cell means across runs
plotCellMeans <- function(data1, data2, name1, name2) {
  # Label facets with name arguments
  data1$bias <- name1
  data2$bias <- name2
  # Generate cell means (assumes dummy coding!)
  # and plot them
  bind_rows(data1, data2) %>% 
    mutate(d1.obs = mod.obs.b1,
           d2.obs = mod.obs.b1 + mod.obs.b2,
           d3.obs = mod.obs.b1 + mod.obs.b3) %>% 
    gather(key, value, d1.obs:d3.obs) %>% 
    ggplot(aes(x = value)) +
    geom_histogram() +
    facet_grid(bias ~ key) +
    scale_x_continuous(limits = c(-.2, 1))
}

# Plot moderator's observed effect size across runs
plotParamMeans <- function(data1, data2, name1, name2) {
  # Label facets with name arguments
  data1$bias <- name1
  data2$bias <- name2
  # plot beta values
  bind_rows(data1, data2) %>% 
    gather(key, value, mod.obs.b2:mod.obs.b3) %>% 
    ggplot(aes(x = value)) +
    geom_histogram() +
    facet_grid(bias ~ key) +
    scale_x_continuous(limits = c(0, 1))  +
    ggtitle("Moderation between d = 0, 0.3, 0.6")
}

# Function for Mean Error
ME = function(dataset, m){
  obs = dataset$d.obs
  mean(m - obs) %>% 
  ggplot(aes())
}

# Function for Root Mean Squared Error
RMSE = function(m, o){
  sqrt(mean((m - o)^2))
  #Label names
  #m = Model_values
  #o = Observed_values
  #plot RMSE
  bind_rows(m, o) %>%
    gather(key, value, d.obs) %>% 
    ggplot(aes(x = value)) +
    geom_histogram() +
    facet_grid(bias ~ key) + 
    scale_x_continuous(limits = c(0, 1)) +
    ggtitle("RMSE")
}
#m is for model (fitted) values, o is for observed (true) values.

#________________________________________________________________________________


#work space below:


```

####*Function output documentation*
##**dataMA**
*k* the number of studies in the MA
*delta* the true effect (or the average of the true effects if heterogeneity exists)
*tau* the SD around the true effect
*empN* a logical, whether to use the empirical per-group N distribution
*maxN* the max possible group size that could be created *this needs to be set higher than what can actually be generated--it doesn't mean you get bigger samples
*minN* the min of the truncated normal for sample size
*meanN* the average of the truncated normal for sample size
*selProp* the proportion of the sample affected by bias
*qrpEnv* the qrp environment that produced the literature: 'none', 'low', 'med', 'high'
*empN.boost* A constant that is added to the empirical effect sizes

*d* effect size d
*p* p value for the two group comparison
*t* t value for the two group comparison
*N* total N
*v* variance for the effect size
*se* standard error for the effect size
*pow* power given the true effect for the two group comparison
*n1* experimental group sample size
*n2* control group sample size

##**inspectMA** 
*d.obs* estimated coefficents of the model
*se.obs* standerd error of the estimate of the overall mean
*d.p* if the observed effect sizes are significantly different?
*mod.b.obs.#* estimated coefficents of the moderator (if dummy codes: difference between one group mean vs. comparison group mean; if contrast codes: difference between one group mean vs. grand average)
*mod.p.#* significance value for the moderation test, significance indicates moderator coefficient unusual for chance
*d.obs.pet* bias-adjusted PET estimate for delta
*p.pet* significance value for the PET estimate, significance indicates bias-adjusted estimate larger than chance
*b.egger* Egger coefficient for relationship between effect size and standard error
*p.egger* significance value for the egger test, significance indicates small-study effects possibly caused by bias
*joint.add.b#* PET-RMA (id+se) adjusted coefficients (grand mean & cell deviations OR cornerstone mean & cell deviations)
*joint.add.b.egger* coefficient of predictor 'se'
*joint.add.p#* significance value for coefficents for the PET-RMA (id+se) test, significance indicates significant bias-adjusted grand mean and/or differences between bias-adjusted subgroup means
*joint.add.p.egger* significance value for the additive effect of the PET-RMA (id+se) test, significance indicates overall small-study effect
*joint.inter.b#* PET-RMA (id*se) adjusted coefficients (grand mean & cell deviations OR cornerstone mean & cell deviations)
*joint.inter.b#.egger* Egger slopes (grand slope & subgroup differences in slope OR cornerstone slope & subgroup differences in slope)
*joint.inter.p#* significance value of the PET-RMA (id*se) adjusted estimates. Significance indicates moderation between bias-adjusted cell means.
*joint.inter.p#.egger* significance value of the interaction for the PET-RMA (id*se) test, significance indicates overall small-study effect or subgroup differences in small-study effects


####*Simulate a meta-analytic dataset with dataMA()*

*Basic Model*
```{r}
#create data
basic.data = dataMA(k = 10, delta = .2, tau = 0, 
               empN = 0, maxN = 200, minN = 20, meanN = 50, 
               selProp = 0, qrpEnv = "none", empN.boost = 0)


#Simulate
basic = rma(yi = d, sei = se, data = basic.data)
#View
summary(basic)
funnel(basic)
forest(basic)
funnel(trimfill(basic))
funnel(basic, level=c(90, 95, 99),
        shade = c("white", "grey75", "grey60"), refline=0)

```

*Null Model*
```{r}
null.data = dataMA(k = 100, delta = 0, tau = 0, 
               empN = 0, maxN = 200, minN = 20, meanN = 50, 
               selProp = 0, qrpEnv = "none", empN.boost = 0)

null = rma(yi = d, sei = se, data = null.data)

summary(null)
funnel(null, level=c(90, 95, 99),
        shade = c("white", "grey75", "grey60"), refline=0)
forest(null)

```

*Bias Model*
*k* the number of studies in the MA
*delta* the true effect (or the average of the true effects if heterogeneity exists)
*tau* the SD around the true effect
*empN* a logical, whether to use the empirical per-group N distribution
*maxN* the max possible group size that could be created *this needs to be set higher than what can actually be generated--it doesn't mean you get bigger samples
*minN* the min of the truncated normal for sample size
*meanN* the average of the truncated normal for sample size

*selProp* the proportion of the sample affected by bias
*qrpEnv* the qrp environment that produced the literature: 'none', 'low', 'med', 'high'
*empN.boost* A constant that is added to the empirical effect sizes
```{r}
selProp.data = dataMA(k = 100, delta = 0, tau = 0, 
               empN = 0, maxN = 200, minN = 20, meanN = 50, 
               selProp = .50, qrpEnv = "none", empN.boost = 0)
selProp1 = rma(yi = d, sei = se, data = selProp.data)

qrpEnv.data = dataMA(k = 100, delta = 0, tau = 0, 
               empN = 0, maxN = 200, minN = 20, meanN = 50, 
               selProp = 0, qrpEnv = "high", empN.boost = 0)
qrpEnv1 = rma(yi = d, sei = se, data = qrpEnv.data)

empN.boost.data = dataMA(k = 100, delta = 0, tau = 0, 
               empN = 0, maxN = 200, minN = 20, meanN = 50, 
               selProp = 0, qrpEnv = "none", empN.boost = .5)
empN.boost1 = rma(yi = d, sei = se, data = empN.boost.data)


funnel(selProp1, level=c(90, 95, 99),
        shade = c("white", "grey75", "grey60"), refline=0, main = "selProp1")
funnel(qrpEnv1, level=c(90, 95, 99),
        shade = c("white", "grey75", "grey60"), refline=0, main = "qrpEvn1")
funnel(empN.boost1, level=c(90, 95, 99),
        shade = c("white", "grey75", "grey60"), refline=0, main = "empN.boost1")


```


*Simulate a moderator effect (meta-regression)*
```{r}
dat <- dataMA(k = 10, delta = .2, tau = 0, 
               empN = 0, maxN = 200, minN = 20, meanN = 50, 
               selProp = 0, qrpEnv = "none", empN.boost = 0)

dat.mod <- data.frame(dat, "mod" = runif(50))
ma5 = rma(yi = d, sei = se, data = dat.mod,
          mods = mod)
summary(ma5)
plot(ma5)

```

